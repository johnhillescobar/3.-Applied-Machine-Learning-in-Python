{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def blight_model():\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Import relevant libraries\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from datetime import datetime\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingClassifier\n",
    "    from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "    from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.svm import SVC\n",
    "    \n",
    "    # Read dataframes\n",
    "    # I included the argument dtype on the training dataset to avoid a DtypeWarning on columns (11, 12, 31)\n",
    "    train = pd.read_csv('readonly/train.csv', encoding='cp1252', \n",
    "                           dtype = {'zip_code': object, 'non_us_str_code': object, 'grafitti_status': object})\n",
    "    test = pd.read_csv('readonly/test.csv', encoding='cp1252')\n",
    "    address = pd.read_csv('readonly/addresses.csv')\n",
    "    latlong = pd.read_csv('readonly/latlons.csv')\n",
    "    \n",
    "    # Join address and latlong in one dataframe.  Then, join address to both train and test data\n",
    "    address = address.set_index('address').join(latlong.set_index('address'), how = 'left')\n",
    "    train = train.set_index('ticket_id').join(address.set_index('ticket_id'), how = 'left')\n",
    "    test = test.set_index('ticket_id').join(address.set_index('ticket_id'), how = 'left')\n",
    "    \n",
    "    # Drop NaN on target value 'compliance' --> we are just looking for compliants and or not compliants\n",
    "    # Although the target variable 'compliance' is dtype('float64'). So, I will adjust it\n",
    "    # to meake it categorical\n",
    "    train = train.dropna(subset = ['compliance'])\n",
    "    train['compliance'] = train['compliance'].astype(int)\n",
    "    \n",
    "    # I created a spreadsheet in which I stored the features I wanted to use on the training and\n",
    "    # and testing dataframes.  Then, I created the mask from there.\n",
    "    #mask = pd.read_excel('model_columns_final.xlsx')\n",
    "    #mask = mask['columnas']\n",
    "    #mask = mask.tolist()\n",
    "    \n",
    "    # I commented out this part of the code as the autograder will get an error from it.\n",
    "    # Instead, I just created a variable called \"mask\", which I used to keep all the attributions \n",
    "    # I will use on this excercise.\n",
    "    \n",
    "    # Create the mask variables with all the variables you want to use\n",
    "    mask = ['hearing_date', \n",
    "            'ticket_issued_date', \n",
    "            'discount_amount',\n",
    "            'disposition', \n",
    "            'fine_amount', \n",
    "            'judgment_amount', \n",
    "            'late_fee', \n",
    "            'state', \n",
    "            'violation_code', \n",
    "            'lat',\n",
    "            'lon',\n",
    "            'compliance']\n",
    "    \n",
    "    # Create the final training dataframe and adjust its data types as well as create a new variable \n",
    "    # named \"date_diff\"\n",
    "    train = train [mask].dropna()\n",
    "    train['hearing_date'] = pd.to_datetime(train['hearing_date'], format = \"%Y-%m-%d %H:%M:%S\")\n",
    "    train['ticket_issued_date'] = pd.to_datetime(train['ticket_issued_date'], format = \"%Y-%m-%d %H:%M:%S\")\n",
    "    train['date_diff'] = (train['hearing_date'] - train['ticket_issued_date'])\n",
    "    train['date_diff'] = train['date_diff'].dt.days\n",
    "    train = train[~train['date_diff'] < 0]\n",
    "    \n",
    "    # Create the final test dataframe and adjust its data types as well as create a new variable \n",
    "    # named \"date_diff\"\n",
    "    mask.remove('compliance')\n",
    "    test = test[mask].dropna()\n",
    "    test['hearing_date'] = pd.to_datetime(test['hearing_date'], format = \"%Y-%m-%d %H:%M:%S\")\n",
    "    test['ticket_issued_date'] = pd.to_datetime(test['ticket_issued_date'], format = \"%Y-%m-%d %H:%M:%S\")\n",
    "    test['date_diff'] = (test['hearing_date'] - test['ticket_issued_date'])\n",
    "    test['date_diff'] = test['date_diff'].dt.days\n",
    "    test = test[~test['date_diff'] < 0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    As a side note, I wanted to document my decision making regarding the attributions\n",
    "    I ended up taking\n",
    "    \n",
    "    1.- By the moment I was selecting the variables, I wanted to add \"zip_code\" attribution but \n",
    "    I noticed that there were 1048 rows with wrong-formatted in the training data.  This is what I got:\n",
    "    \n",
    "        5.0     158831\n",
    "        4.0        638\n",
    "        6.0        138\n",
    "        1.0        107\n",
    "        3.0         60\n",
    "        10.0        54\n",
    "        9.0         29\n",
    "        2.0         12\n",
    "        7.0          7\n",
    "        8.0          3\n",
    "        Name: zip, dtype: int64\n",
    "    \n",
    "    The \"zip\" attribution I created, measured the lenght of each zip code\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return test.head(2)\n",
    "\n",
    "blight_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
